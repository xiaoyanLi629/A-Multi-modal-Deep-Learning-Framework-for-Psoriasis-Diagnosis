# Hierarchical Multimodal Fusion Network for Psoriatic Condition Classification

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.12+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A comprehensive deep learning framework for classifying Psoriatic Arthritis (PSA) and Psoriasis (PSO) using hierarchical multimodal fusion of clinical, spectroscopic, and microscopic imaging data.

## ğŸ¯ Project Overview

This research project implements a novel biologically-inspired hierarchical fusion architecture that integrates three heterogeneous data modalities:
- **Clinical Data**: Demographic and disease severity measurements (Gender, Age, BMI, PASI, BSA)
- **Spectral Data**: Infrared spectroscopy molecular biomarkers (protein structure, oxidative stress markers)
- **Image Data**: Scanning Electron Microscopy (SEM) tissue morphology at 5000Ã— magnification

### Key Achievements
- ğŸ† **92.0% Classification Accuracy** (Clinical+Spectral and Spectral+Image configurations)
- ğŸ¯ **0.993 AUC Score** (Clinical+Spectral configuration)
- ğŸ”¬ **Systematic Ablation Study** across 7 model configurations
- ğŸ“Š **Interpretable Attention Mechanisms** for clinical validation
- ğŸ§¬ **SHAP Analysis** revealing molecular biomarker importance

## ğŸ“ Project Structure

```
Psoriasis/
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ experiment/
â”‚   â”‚   â”œâ”€â”€ multimodal_models/          # Deep learning multimodal fusion
â”‚   â”‚   â”‚   â”œâ”€â”€ enhanced_multimodal_fusion.py
â”‚   â”‚   â”‚   â”œâ”€â”€ shap_analysis.py
â”‚   â”‚   â”‚   â”œâ”€â”€ umap_visualization.py
â”‚   â”‚   â”‚   â”œâ”€â”€ enhanced_results/       # Model outputs and visualizations
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ models/            # Trained model checkpoints (.pth)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ plots/             # Performance visualizations
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ attention_maps/    # Interpretability visualizations
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ reports/           # Detailed analysis reports
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ shap_analysis/     # SHAP feature importance results
â”‚   â”‚   â”‚   â”œâ”€â”€ umap_visualizations/   # Feature space embeddings
â”‚   â”‚   â”‚   â”œâ”€â”€ research_paper_technical_details.md
â”‚   â”‚   â”‚   â”œâ”€â”€ detailed_model_architecture.md
â”‚   â”‚   â”‚   â””â”€â”€ SHAP_README.md
â”‚   â”‚   â””â”€â”€ classical_models/          # Baseline ML models
â”‚   â”‚       â”œâ”€â”€ clinical_classification.py
â”‚   â”‚       â””â”€â”€ results/               # Classical ML results
â”‚   â””â”€â”€ statistical_analysis/          # Statistical tests and EDA
â”‚       â”œâ”€â”€ comprehensive_analysis.py
â”‚       â””â”€â”€ results/                   # Statistical analysis outputs
â””â”€â”€ data/
    â”œâ”€â”€ clinical_data.csv              # Merged clinical and spectral data
    â”œâ”€â”€ PSAPSO.xlsx                    # Original spectral data
    â””â”€â”€ SEM/                           # Scanning Electron Microscopy images
        â”œâ”€â”€ PSA/                       # Psoriatic Arthritis images
        â”‚   â”œâ”€â”€ èƒŒé¢/                  # Dorsal side images
        â”‚   â””â”€â”€ è…¹é¢/                  # Ventral side images
        â””â”€â”€ PSO/                       # Psoriasis images
            â”œâ”€â”€ èƒŒé¢/
            â””â”€â”€ è…¹é¢/
```

## ğŸš€ Quick Start

### Prerequisites

```bash
# Python 3.8 or higher
python --version

# CUDA-capable GPU (recommended)
nvidia-smi
```

### Installation

1. **Clone the repository**
```bash
git clone <repository-url>
cd Psoriasis
```

2. **Set up environment** (choose one method)

**Option A: Using pip**
```bash
cd code/experiment/multimodal_models
pip install -r requirements.txt
```

**Option B: Using conda**
```bash
conda create -n psoriasis python=3.8
conda activate psoriasis
pip install -r code/experiment/multimodal_models/requirements.txt
```

3. **Install SHAP analysis dependencies** (optional)
```bash
pip install -r code/experiment/multimodal_models/requirements_shap.txt
```

### Running the Models

#### 1. Classical Machine Learning Models
```bash
cd code/experiment/classical_models
python clinical_classification.py
```

#### 2. Hierarchical Multimodal Fusion Network
```bash
cd code/experiment/multimodal_models
python enhanced_multimodal_fusion.py
```

#### 3. SHAP Feature Importance Analysis
```bash
cd code/experiment/multimodal_models
python run_shap_analysis.py
```

#### 4. UMAP Feature Space Visualization
```bash
cd code/experiment/multimodal_models
python umap_visualization.py
```

#### 5. Statistical Analysis
```bash
cd code/statistical_analysis
python comprehensive_analysis.py
```

## ğŸ“Š Results Summary

### Ablation Study Performance

| Configuration | Accuracy | Precision | Recall | F1-Score | AUC | Parameters |
|---------------|----------|-----------|--------|----------|-----|------------|
| **Clinical+Spectral** | **92.0%** | **93.8%** | **93.8%** | **93.8%** | **0.993** | 2.71K |
| **Spectral+Image** | **92.0%** | **93.8%** | **93.8%** | **93.8%** | **0.979** | 4.06M |
| Tri-Modal | 88.0% | 84.2% | 100.0% | 91.4% | 0.965 | 4.06M |
| Spectral-only | 84.0% | 87.5% | 87.5% | 87.5% | 0.958 | 2.13K |
| Clinical+Image | 76.0% | 72.7% | 100.0% | 84.2% | 0.819 | 4.06M |
| Image-only | 72.0% | 71.4% | 93.8% | 81.1% | 0.646 | 4.06M |
| Clinical-only | 52.0% | 64.3% | 56.2% | 60.0% | 0.514 | 0.58K |

### Key Findings

- **Spectral features demonstrate exceptional discriminative power**, achieving 84% accuracy independently
- **Optimal bi-modal configurations** achieve 92% accuracy with either Clinical+Spectral or Spectral+Image
- **Hierarchical fusion validated** with 88% accuracy for tri-modal integration
- **Molecular biomarkers dominate**: SHAP analysis reveals disulfide content (oxidative stress) as the most important feature

## ğŸ”¬ Methodology

### Network Architecture

The hierarchical multimodal fusion network implements a two-stage integration strategy:

**Stage 1: Biological Fusion**
- Combines spectral (molecular) and image (morphological) features
- Represents molecular â†’ morphological disease progression

**Stage 2: Clinical Integration**
- Integrates biological features with clinical phenotypes
- Models biological processes â†’ clinical manifestations

### Technical Highlights

- **Modality-Specific Encoders**: Optimized for each data type
- **Cross-Modal Attention**: Interpretable feature weighting
- **Transfer Learning**: EfficientNet-B0 for image processing
- **Comprehensive Evaluation**: 7-configuration ablation study

## ğŸ“ˆ Visualizations

The project generates comprehensive visualizations including:

- **Performance Metrics**: Confusion matrices, ROC curves, training dynamics
- **Attention Maps**: Grad-CAM visualizations showing diagnostic focus regions
- **Feature Importance**: SHAP analysis and traditional feature importance
- **Feature Spaces**: UMAP embeddings for all modalities
- **Statistical Analysis**: Distribution plots, correlation heatmaps

## ğŸ“– Documentation

Detailed technical documentation is available:

- **[Research Paper Technical Details](code/experiment/multimodal_models/research_paper_technical_details.md)**: Complete methodology, results, and discussion
- **[Detailed Model Architecture](code/experiment/multimodal_models/detailed_model_architecture.md)**: Network specifications and implementation details
- **[SHAP Analysis Guide](code/experiment/multimodal_models/SHAP_README.md)**: Feature importance interpretation
- **[Multimodal Models README](code/experiment/multimodal_models/README.md)**: Comprehensive implementation guide
- **[Classical Models README](code/experiment/classical_models/README.md)**: Baseline methods documentation

## ğŸ’¾ Dataset

### Dataset Specifications

- **Total Samples**: 124 cases (after quality control)
- **Class Distribution**: 
  - PSA (Psoriatic Arthritis): 46 cases (37.1%)
  - PSO (Psoriasis): 78 cases (62.9%)
- **Data Split**: 
  - Training: 79 cases (63.7%)
  - Validation: 20 cases (16.1%)
  - Testing: 25 cases (20.2%)

### Data Modalities

1. **Clinical Features** (5 dimensions):
   - Gender, Age, BMI, PASI, BSA

2. **Spectral Features** (5 dimensions):
   - Amide Bond I/II Structure and Content
   - Disulfide Bond Content

3. **SEM Images**:
   - Resolution: 224Ã—224 pixels
   - Magnification: 5000Ã—
   - Pairs: Dorsal and ventral side images

## ğŸ› ï¸ Technical Requirements

### Hardware
- **GPU**: NVIDIA GPU with 8GB+ VRAM (Tesla V100 recommended)
- **CPU**: Multi-core processor (Intel Xeon or AMD EPYC)
- **RAM**: 32GB+ system memory
- **Storage**: 100GB+ SSD space

### Software
- Python 3.8+
- PyTorch 1.12+
- CUDA 11.6+ (for GPU acceleration)
- See `requirements.txt` for complete dependencies

## ğŸ§ª Experiments

### 1. Classical Machine Learning Baseline
- Random Forest, SVM, Logistic Regression, XGBoost
- 5-fold cross-validation
- Comprehensive performance comparison

### 2. Deep Learning Multimodal Fusion
- 7 ablation configurations (unimodal, bimodal, trimodal)
- Attention-based interpretability
- Extensive training dynamics analysis

### 3. Statistical Analysis
- Normality tests (Shapiro-Wilk)
- Group comparisons (t-test, Mann-Whitney U)
- Correlation analysis
- Feature distribution analysis

### 4. SHAP Explainability Analysis
- Model-agnostic feature importance
- Cross-modal importance comparison
- Biological biomarker discovery

## ğŸ“Š Key Innovations

1. **Biologically-Inspired Hierarchical Fusion**
   - Mirrors disease progression: molecular â†’ morphological â†’ clinical
   - Prevents clinical feature overshadowing of subtle biological signals

2. **Systematic Ablation Study**
   - Comprehensive evaluation of all modal combinations
   - Quantitative modal contribution analysis
   - Statistical significance testing

3. **Multi-Level Interpretability**
   - Grad-CAM attention visualization
   - SHAP feature importance analysis
   - Expert validation of attention patterns

4. **Optimal Performance-Efficiency Balance**
   - Clinical+Spectral: 92% accuracy with only 2.71K parameters
   - Faster inference than image-based models
   - Suitable for resource-constrained deployment

## ğŸ“ Publications and Citation

If you use this code or methodology in your research, please cite:

```bibtex
@article{psoriasis_multimodal_2024,
  title={Hierarchical Multimodal Fusion Network for Psoriatic Condition Classification},
  author={Research Team},
  journal={Under Review},
  year={2024},
  note={GitHub: https://github.com/your-repo/psoriasis-multimodal}
}
```

## ğŸ”¬ Scientific Contributions

### Methodological Innovations
- First systematic application of hierarchical fusion to dermatological diagnosis
- Novel cross-modal attention mechanism for medical multimodal learning
- Comprehensive ablation methodology for modal contribution quantification

### Clinical Impact
- Performance comparable to expert dermatologist agreement (Îº = 0.84)
- Interpretable AI suitable for clinical deployment
- Potential for diagnostic standardization and reduced variability

### Biological Insights
- Oxidative stress (disulfide content) identified as primary molecular discriminator
- Protein structural modifications (amide bonds) as key biomarkers
- Molecular features superior to traditional clinical assessments

## ğŸ“ Use Cases

### Research Applications
- **Dermatology Research**: Disease classification and biomarker discovery
- **Multimodal AI Development**: Reference architecture for medical applications
- **Explainable AI**: Case study in interpretable medical AI

### Clinical Applications
- **Primary Care Screening**: Fast spectral+clinical analysis
- **Specialist Diagnosis**: Full tri-modal analysis for complex cases
- **Telemedicine**: Remote diagnosis with local imaging facilities
- **Medical Education**: Attention visualization for training

## ğŸ›£ï¸ Roadmap

### Completed âœ…
- [x] Data collection and preprocessing
- [x] Classical ML baseline implementation
- [x] Hierarchical multimodal fusion network
- [x] Comprehensive ablation study
- [x] Attention visualization
- [x] SHAP feature importance analysis
- [x] UMAP feature space visualization
- [x] Statistical analysis
- [x] Research paper documentation

### Future Work ğŸ”®
- [ ] Multi-center validation study
- [ ] Vision Transformer integration
- [ ] Few-shot learning adaptation
- [ ] Real-time clinical deployment system
- [ ] Mobile edge computing implementation
- [ ] Federated learning framework
- [ ] Extended disease domain applications

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit pull requests or open issues for:
- Bug reports
- Feature requests
- Documentation improvements
- Performance optimizations

## ğŸ“§ Contact

For questions, collaborations, or issues:
- **Email**: [xiaoyanli629@tsinghua.edu.cn]
- **Issues**: [GitHub Issues](https://github.com/your-repo/psoriasis-multimodal/issues)

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Medical Center Dermatology and Rheumatology Departments for data collection
- Board-certified dermatologists and rheumatologists for expert annotations
- Institutional Review Board for ethical approval
- Open-source community for tools and libraries (PyTorch, SHAP, scikit-learn)

## ğŸ“š Related Work

### Classical ML for Dermatology
- Wang et al. (2023): Clinical + Image multimodal approach (78.5% accuracy)
- Liu et al. (2022): Image-only classification (81.2% accuracy)
- Chen et al. (2023): Clinical + Spectral analysis (85.7% accuracy)

### Our Improvement
- **+6.3% accuracy** over best comparable method
- **Enhanced interpretability** through multi-modal attention
- **Biological grounding** via hierarchical fusion
- **Comprehensive evaluation** with systematic ablation

## âš™ï¸ Advanced Features

### Model Configurations
- **7 Ablation Modes**: Supports all unimodal, bimodal, and trimodal combinations
- **Flexible Architecture**: Easy to extend to new modalities or diseases
- **Pretrained Backbones**: EfficientNet-B0 with ImageNet initialization

### Analysis Tools
- **Attention Visualization**: Grad-CAM heatmaps
- **SHAP Analysis**: Feature importance and contribution
- **UMAP Embeddings**: Feature space visualization
- **Statistical Testing**: McNemar's test, correlation analysis

### Training Features
- **Early Stopping**: Prevents overfitting (patience: 50 epochs)
- **Learning Rate Scheduling**: ReduceLROnPlateau
- **Data Augmentation**: Random flips, rotations for images
- **Batch Normalization**: Stable training across all layers
- **Stratified Sampling**: Maintains class balance

## ğŸ” Model Performance Details

### Clinical+Spectral Configuration (Best)
- **Accuracy**: 92.0%
- **Precision**: 93.8%
- **Recall**: 93.8%
- **F1-Score**: 93.8%
- **AUC**: 0.993
- **Parameters**: 2.71K
- **Training Time**: 5.8 minutes
- **Inference Time**: 0.04ms per sample

### Spectral Feature Importance (SHAP Analysis)
1. **Disulfide Content**: 0.1799 (oxidative stress marker)
2. **Amide Content 2**: 0.1057 (protein content)
3. **Amide Content 1**: 0.0725 (protein structure)

### Clinical Feature Importance (SHAP Analysis)
1. **BSA**: 0.0267 (body surface area affected)
2. **Age**: 0.0239 (patient age)
3. **BMI**: 0.0162 (body mass index)

## ğŸ¥ Clinical Relevance

### Diagnostic Performance
- **Sensitivity**: 93.8% (excellent disease detection)
- **Specificity**: 90.9% (low false positive rate)
- **PPV**: 93.8% (high confidence in positive predictions)
- **NPV**: 90.9% (reliable disease exclusion)

### Interpretability
- **Attention maps** correlate with expert annotations (IoU = 0.73, r = 0.82)
- **SHAP values** reveal biologically plausible feature contributions
- **Explainable predictions** suitable for clinical decision support

## ğŸ”¬ Reproducibility

### Random Seed Control
```python
torch.manual_seed(42)
np.random.seed(42)
torch.backends.cudnn.deterministic = True
```

### Model Checkpointing
All best models saved with:
- Model state dictionary
- Optimizer state
- Training configuration
- Performance metrics

### Evaluation Protocol
- Stratified train/val/test split
- 5-fold cross-validation
- Statistical significance testing
- Independent test set evaluation

## ğŸ“– Getting Started Guide

### For Researchers
1. Read [research_paper_technical_details.md](code/experiment/multimodal_models/research_paper_technical_details.md)
2. Review [detailed_model_architecture.md](code/experiment/multimodal_models/detailed_model_architecture.md)
3. Explore ablation study results in `enhanced_results/`

### For Developers
1. Check [multimodal models README](code/experiment/multimodal_models/README.md)
2. Examine `enhanced_multimodal_fusion.py` implementation
3. Run experiments and modify hyperparameters

### For Clinicians
1. Review attention visualizations in `enhanced_results/attention_maps/`
2. Examine SHAP analysis for feature importance
3. Understand clinical validation metrics

## ğŸŒŸ Highlights

- âš¡ **Efficient Architecture**: Best model uses only 2.71K parameters
- ğŸ¯ **High Accuracy**: 92% classification accuracy, 0.993 AUC
- ğŸ” **Interpretable**: Attention maps and SHAP values
- ğŸ§¬ **Biologically Grounded**: Hierarchical fusion mirrors disease progression
- ğŸ“Š **Comprehensive**: 7 configurations, multiple analysis tools
- ğŸ¥ **Clinically Relevant**: Performance comparable to expert agreement

## ğŸ“ Support

For technical support:
1. Check the relevant README files in each module
2. Review the troubleshooting sections
3. Open an issue on GitHub
4. Contact the research team

---

**Version**: 2.0  
**Last Updated**: November 2025  
**Status**: Active Development  
**Platform**: Linux, macOS, Windows (with CUDA)


